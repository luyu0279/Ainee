import json
import logging
from typing import Optional, TypedDict

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from pydantic import BaseModel, Field

from app.database.config import config_repository
from app.libs.llm.index import llm
from app.libs.llm.tool_define import get_available_tools

logger = logging.getLogger(__name__)


async def get_follow_up_question_prompt():
    system_config = await config_repository.get_config()

    return ChatPromptTemplate.from_messages(
        [

            ("system", system_config.follow_up_question_prompt),
            ("user",
             "Please start generating, and make sure the question is short and concise, and in the voice of use.")
            # MessagesPlaceholder(variable_name="chat_history"),
        ]
    )


class FollowUpQuestion(BaseModel):
    """Follow-up questions generated by the model"""
    questions: list[str] = Field(description="Follow up questions")

    def to_json(self):
        return json.dumps(self.questions, ensure_ascii=False)


follow_up_structured_llm = llm.with_structured_output(FollowUpQuestion)


async def generate_follow_up(device_id, latest_user_message: Optional[str],
                             latest_ai_answer: Optional[str]) -> FollowUpQuestion:
    # chat_history = await get_messages_by_session_id(device_id, 4).aget_messages()
    follow_up_question_prompt = await get_follow_up_question_prompt()
    follow_up_prompt = await follow_up_question_prompt.ainvoke({
        "chat_history": [],
        "available_tools": json.dumps([_tool.name for _tool in get_available_tools()]),
        "latest_user_message": latest_user_message or "",
        "latest_ai_message": latest_ai_answer or ""
    })
    return await follow_up_structured_llm.ainvoke(follow_up_prompt)
